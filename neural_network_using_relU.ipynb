{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "neural_network.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "140Jxc-GK0GcW7-3Eft9tBuSBNtBXvI-S",
      "authorship_tag": "ABX9TyNErOSuahpRz2lMeK7nbpmu",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ojas1804/neural-networks/blob/main/neural_network.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "umHwpmuetOXD"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **GET DATA**"
      ],
      "metadata": {
        "id": "uBE7-2gb0Bpu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_data=pd.read_csv(\"/content/drive/MyDrive/CSV_Files/NN_Data/mnist_train.csv\", header=None)\n",
        "test_data=pd.read_csv(\"/content/drive/MyDrive/CSV_Files/NN_Data/mnist_test.csv\", header=None)"
      ],
      "metadata": {
        "id": "u4EQQKg5tXcw"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **DEFINE NEURAL NETWORK**"
      ],
      "metadata": {
        "id": "dd3AphfD0PiU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ANN:\n",
        "\n",
        "    def __init__(self, iters, alpha, layers, node_per_layer):\n",
        "        self.iters = iters\n",
        "        self.alpha = alpha # learning rate\n",
        "        self.layers = layers\n",
        "        self.node_per_layer = node_per_layer\n",
        "        self.weights, self.bias = self.initialize_parameters()\n",
        "        # self.weights = self.initialize_parameters()\n",
        "\n",
        "\n",
        "    def initialize_parameters(self):\n",
        "        weights = {}\n",
        "        bias = {}\n",
        "        W0 = np.random.randn(784, self.node_per_layer[0]) / np.sqrt(784)\n",
        "        W1 = np.random.randn(self.node_per_layer[0], self.node_per_layer[1]) / np.sqrt(self.node_per_layer[0])\n",
        "        W2 = np.random.randn(self.node_per_layer[1], self.node_per_layer[2]) / np.sqrt(self.node_per_layer[1])\n",
        "        W3 = np.random.randn(self.node_per_layer[2], 10) / np.sqrt(self.node_per_layer[2])\n",
        "        weights[\"W0\"] = W0\n",
        "        weights[\"W1\"] = W1\n",
        "        weights[\"W2\"] = W2\n",
        "        weights[\"W3\"] = W3\n",
        "\n",
        "        B0 = np.random.randn(1, self.node_per_layer[0])\n",
        "        B1 = np.random.randn(1, self.node_per_layer[1])\n",
        "        B2 = np.random.randn(1, self.node_per_layer[2])\n",
        "        B3 = np.random.randn(1, 10)\n",
        "        bias[\"B0\"] = B0\n",
        "        bias[\"B1\"] = B1\n",
        "        bias[\"B2\"] = B2\n",
        "        bias[\"B3\"] = B3\n",
        "\n",
        "        return weights, bias\n",
        "\n",
        "\n",
        "    # UTILITY FUNCTIONS\n",
        "    def relu(self, Z):\n",
        "        return np.maximum(0, Z)\n",
        "\n",
        "\n",
        "    def diff_relu(self, Z):\n",
        "        return Z > 0\n",
        "\n",
        "\n",
        "    def softmax(self, Z):\n",
        "        exp_scores = np.exp(Z - Z.max())\n",
        "        probs = exp_scores / np.sum(exp_scores, axis=1, keepdims=True)\n",
        "        return probs\n",
        "\n",
        "\n",
        "    def diff_softmax(self, Z):\n",
        "        exp_scores = np.exp(Z - Z.max())\n",
        "        return exp_scores / np.sum(exp_scores, axis=1, keepdims=True) * (1 - exp_scores / np.sum(exp_scores, axis=1, keepdims=True))\n",
        "\n",
        "\n",
        "    def error_calculation(self, out, y):\n",
        "        return 1/(2 * 10) * np.sum((out - y)**2)\n",
        "\n",
        "\n",
        "    def sigmoid(self, Z):\n",
        "        return 1/(1 + np.exp(-Z))\n",
        "\n",
        "\n",
        "    def diff_sigmoid(self, Z):\n",
        "        return (np.exp(-Z))/((np.exp(-Z)+1)**2)\n",
        "\n",
        "\n",
        "    def one_hot_encode(self, y):\n",
        "        arr = [0] * 10\n",
        "        arr[y[0]] = 1\n",
        "        return np.array(arr)\n",
        "\n",
        "\n",
        "    def calculate_accuracy(self, out, y):\n",
        "        out = np.array(out)\n",
        "        out = out.reshape(out.shape[0], 1)\n",
        "        y_ = y.reshape(y.shape[0], 1)\n",
        "        sum = 0\n",
        "        for i in range(y.shape[0]):\n",
        "            if(out[i] == y_[i]):\n",
        "                sum = sum + 1\n",
        "        return sum/ y_.shape[0] * 100\n",
        "\n",
        "\n",
        "    # FORWARD PASS\n",
        "    def forward_pass(self, x):\n",
        "        # convert input to 2-d array using reshape\n",
        "        x = x.values.reshape(1, 784)\n",
        "\n",
        "        Z1 = x.dot(self.weights[\"W0\"]) + self.bias[\"B0\"]\n",
        "        A1 = self.relu(Z1)\n",
        "\n",
        "        Z2 = A1.dot(self.weights[\"W1\"]) + self.bias[\"B1\"]\n",
        "        A2 = self.relu(Z2)\n",
        "\n",
        "        Z3 = A2.dot(self.weights[\"W2\"]) + self.bias[\"B2\"]\n",
        "        A3 = self.relu(Z3)\n",
        "\n",
        "        Z4 = A3.dot(self.weights[\"W3\"]) + self.bias[\"B3\"]\n",
        "        A4 = self.softmax(Z4)\n",
        "\n",
        "        Z = (Z1, Z2, Z3, Z4)\n",
        "        A = (A1, A2, A3, A4)\n",
        "        return A, Z\n",
        "\n",
        "\n",
        "    # BACK PROPAGATION\n",
        "    def back_prop(self, x, y_, A, Z):\n",
        "        y_ = self.one_hot_encode(y_).reshape(1, 10)\n",
        "\n",
        "        dK4 = 2 / 10 * (A[3] - y_) * self.diff_softmax(Z[3])\n",
        "        dB3 = np.sum(dK4, axis=0, keepdims=True)\n",
        "        dW3 = np.outer(dK4.T, A[2].T)\n",
        "        \n",
        "        dK3 = (dK4).dot(self.weights[\"W3\"].T) * self.diff_relu(Z[2])\n",
        "        dB2 = np.sum(dK3, axis=0)\n",
        "        dW2 = np.outer(dK3.T, A[1].T)\n",
        "\n",
        "        dK2 = (dK3).dot(self.weights[\"W2\"].T) * self.diff_relu(Z[1])\n",
        "        dB1 = np.sum(dK2, axis=0)\n",
        "        dW1 = np.outer(dK2.T, A[0].T)\n",
        "\n",
        "        x = x.values.reshape(1, 784)\n",
        "        dK1 = (dK2).dot(self.weights[\"W1\"].T) * self.diff_relu(Z[0])\n",
        "        dB0 = np.sum(dK1, axis=0)\n",
        "        dW0 = np.outer(dK1.T, x.T)\n",
        "\n",
        "        # dW3 += 0.05 * self.weights[\"W3\"]\n",
        "        # dW2 += 0.05 * self.weights[\"W2\"]\n",
        "        # dW1 += 0.05 * self.weights[\"W1\"]\n",
        "        # dW0 += 0.05 * self.weights[\"W0\"]\n",
        "\n",
        "        dW = (dW0, dW1, dW2, dW3)\n",
        "        dB = (dB0, dB1, dB2, dB3)\n",
        "        return dW, dB\n",
        "\n",
        "\n",
        "    # UPDATE PARAMETERS\n",
        "    def update_parameters(self, dW, dB):\n",
        "        self.weights[\"W0\"] = self.weights[\"W0\"] - (self.alpha * dW[0].T)\n",
        "        self.weights[\"W1\"] = self.weights[\"W1\"] - (self.alpha * dW[1].T)\n",
        "        self.weights[\"W2\"] = self.weights[\"W2\"] - (self.alpha * dW[2].T)\n",
        "        self.weights[\"W3\"] = self.weights[\"W3\"] - (self.alpha * dW[3].T)\n",
        "        # print(self.weights[\"W3\"])\n",
        "\n",
        "        self.bias[\"B0\"] = self.bias[\"B0\"] - (self.alpha * dB[0])\n",
        "        self.bias[\"B1\"] = self.bias[\"B1\"] - (self.alpha * dB[1])\n",
        "        self.bias[\"B2\"] = self.bias[\"B2\"] - (self.alpha * dB[2])\n",
        "        self.bias[\"B3\"] = self.bias[\"B3\"] - (self.alpha * dB[3])\n",
        "\n",
        "\n",
        "    # TRAIN\n",
        "    def train_model(self, X, y):\n",
        "        y = y.reshape(y.shape[1], 1)\n",
        "        for i in range(self.iters):\n",
        "            predictions = []\n",
        "            print(f\"ITERATION {i + 1} : \")\n",
        "            for j in range(y.shape[0]):\n",
        "                x = X.iloc[j]\n",
        "                A, Z = self.forward_pass(x)\n",
        "                prediction = np.argmax(A[3])\n",
        "                predictions.append(prediction)\n",
        "\n",
        "                dW, dB = self.back_prop(x, y[j], A, Z)\n",
        "                self.update_parameters(dW, dB)\n",
        "            print(\"     Accuracy : \", self.calculate_accuracy(predictions, y), \"%\")\n",
        "            predictions.clear()\n",
        "            print(\"-\" * 40)\n",
        "\n",
        "\n",
        "    # TEST\n",
        "    def test_model(self, X_test, y_test):\n",
        "        predictions = []\n",
        "        y_test = y_test.reshape(y_test.shape[1], 1)\n",
        "        for i in range(y_test.shape[0]):\n",
        "            A, Z = self.forward_pass(X_test.iloc[i])\n",
        "            prediction = np.argmax(A[3])\n",
        "            predictions.append(prediction)\n",
        "        print(\"        ACCURACY ON TEST DATASET:\")\n",
        "        print(\"Accuracy:\", self.calculate_accuracy(predictions, y_test), \"%\")\n",
        "            "
      ],
      "metadata": {
        "id": "7Huy_xkooi2O"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **NORMALIZING DATA**"
      ],
      "metadata": {
        "id": "3PESnCEeF9MY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_train = train_data.iloc[:, 0]\n",
        "y_train = y_train.values.reshape(1, y_train.shape[0])\n",
        "print(y_train.shape)\n",
        "X_train = train_data.iloc[:, 1:]\n",
        "X_train = (X_train/255).astype(\"float32\")\n",
        "\n",
        "y_test = test_data.iloc[:, 0]\n",
        "y_test = y_test.values.reshape(1, y_test.shape[0])\n",
        "X_test = test_data.iloc[:, 1:]\n",
        "X_test = (X_test/255).astype(\"float32\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZpxtWNX5NFyq",
        "outputId": "7d4bf1fe-60aa-4e4f-ef77-fd9930cd606e"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1, 60000)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "iters = 5\n",
        "alpha = 0.1\n",
        "layers = 3\n",
        "node_per_layer = [261, 87, 29]\n",
        "ann = ANN(iters, alpha, layers, node_per_layer)\n",
        "ann.train_model(X_train, y_train)\n",
        "ann.test_model(X_test, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VFcdksVvBUmh",
        "outputId": "8916ad2a-c0c0-478e-a732-d32f31770df9"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ITERATION 1 : \n",
            "     Accuracy :  89.12166666666667 %\n",
            "----------------------------------------\n",
            "ITERATION 2 : \n",
            "     Accuracy :  95.98666666666666 %\n",
            "----------------------------------------\n",
            "ITERATION 3 : \n",
            "     Accuracy :  97.19333333333333 %\n",
            "----------------------------------------\n",
            "ITERATION 4 : \n",
            "     Accuracy :  97.81833333333333 %\n",
            "----------------------------------------\n",
            "ITERATION 5 : \n",
            "     Accuracy :  98.295 %\n",
            "----------------------------------------\n",
            "        ACCURACY ON TEST DATASET:\n",
            "Accuracy: 97.06 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "_Rv4KiTjj1_Q"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
